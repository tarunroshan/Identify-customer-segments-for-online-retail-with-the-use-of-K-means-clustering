{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fb4dc3",
   "metadata": {},
   "source": [
    "# Work Environment & Data Preparation Template\n",
    "\n",
    "**Project:** Identify Customer Segments for Online Retail using K-Means Clustering\n",
    "\n",
    "**Name:** Gali Tarun Roshan\n",
    "\n",
    "**Role:** Data Science Intern\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports for data prep and EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ebd86",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Load the Data\n",
    "\n",
    "Place your dataset in a `data/` folder (e.g., `data/online_retail.csv`).\n",
    "\n",
    "Supported formats: CSV, Excel, or SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load CSV\n",
    "# df = pd.read_csv('data/online_retail.csv', encoding='latin1')\n",
    "# For Excel: df = pd.read_excel('data/online_retail.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Placeholder: create a small sample DataFrame if file not present\n",
    "data = {\n",
    "    'CustomerID': [12345, 12346, 12347, 12348, 12345],\n",
    "    'InvoiceNo': ['A001', 'A002', 'A003', 'A004', 'A005'],\n",
    "    'InvoiceDate': pd.to_datetime(['2020-01-05','2020-01-07','2020-02-01','2020-02-05','2020-03-01']),\n",
    "    'Quantity': [10, 5, 2, 1, 3],\n",
    "    'UnitPrice': [2.5, 5.0, 1.25, 10.0, 2.5],\n",
    "    'Country': ['United Kingdom','France','United Kingdom','Germany','United Kingdom']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54d16a",
   "metadata": {},
   "source": [
    "## 3. Understand the Data\n",
    "\n",
    "Run basic checks: head, info, describe, nulls, duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e47b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "print('Shape:', df.shape)\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "# Missing values & duplicates\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "print('\\nDuplicate rows:', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba92360",
   "metadata": {},
   "source": [
    "## 4. Clean the Data\n",
    "\n",
    "Handle missing values, duplicates, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24078137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates example\n",
    "df_clean = df.drop_duplicates().copy()\n",
    "\n",
    "# Convert types if necessary (example)\n",
    "df_clean['CustomerID'] = df_clean['CustomerID'].astype(str)\n",
    "\n",
    "# Handle missing values (example strategy)\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# df_clean['Quantity'] = imputer.fit_transform(df_clean[['Quantity']])\n",
    "\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ec03d",
   "metadata": {},
   "source": [
    "## 5. Transform the Data\n",
    "\n",
    "Scaling and encoding examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: TotalPrice\n",
    "df_clean['TotalPrice'] = df_clean['Quantity'] * df_clean['UnitPrice']\n",
    "\n",
    "# Scaling numeric features (example)\n",
    "numeric_features = ['Quantity', 'UnitPrice', 'TotalPrice']\n",
    "scaler = StandardScaler()\n",
    "df_clean[numeric_features] = scaler.fit_transform(df_clean[numeric_features])\n",
    "\n",
    "# Encoding categorical features (example)\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Country'], drop_first=True)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926d57b",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "\n",
    "Example: Create RFM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example RFM features for customer segmentation\n",
    "# For real data, ensure InvoiceDate is datetime and CustomerID exists\n",
    "snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "rfm = df.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'TotalPrice': lambda x: (x*1).sum() if 'TotalPrice' in df.columns else (df.loc[x.index,'Quantity']*df.loc[x.index,'UnitPrice']).sum()\n",
    "}).reset_index()\n",
    "\n",
    "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "rfm['CustomerID'] = rfm['CustomerID'].astype(str)\n",
    "display(rfm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33342e69",
   "metadata": {},
   "source": [
    "## 7. Feature Selection & Save Cleaned Data\n",
    "\n",
    "Select features for clustering and save normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features (example)\n",
    "features = ['Recency', 'Frequency', 'Monetary']\n",
    "rfm_selected = rfm[features].fillna(0)\n",
    "\n",
    "# Normalize\n",
    "mms = MinMaxScaler()\n",
    "rfm_norm = pd.DataFrame(mms.fit_transform(rfm_selected), columns=features)\n",
    "rfm_norm.head()\n",
    "\n",
    "# Save to CSV for submission\n",
    "rfm_norm.to_csv('cleaned_normalized_features_Gali_Tarun_Roshan.csv', index=False)\n",
    "print('Saved cleaned normalized features to cleaned_normalized_features_Gali_Tarun_Roshan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431473ad-e6a6-4e10-a2ad-96e7d91e7556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345620d-bcd0-4d4f-ba2a-200290bb5e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the dataset (replace with your actual dataset name)\n",
    "data = pd.read_csv('OnlineRetail_Clean.csv')\n",
    "data.head()\n",
    "\n",
    "# --- Step 1: Standardize the Data ---\n",
    "features = data.select_dtypes(include=[np.number])  # select only numeric columns\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=features.columns)\n",
    "scaled_df.head()\n",
    "\n",
    "# --- Step 2: Determine the Optimal Number of Clusters (Elbow Method) ---\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(scaled_df)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method - Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# --- Step 3: Run K-Means Clustering ---\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(scaled_df)\n",
    "\n",
    "# --- Step 4: Visualize the Clusters ---\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=scaled_df.iloc[:, 0], y=scaled_df.iloc[:, 1], hue=data['Cluster'], palette='pastel')\n",
    "plt.title('Customer Segments Visualization')\n",
    "plt.show()\n",
    "\n",
    "# --- Step 5: Analyze and Profile Each Cluster ---\n",
    "cluster_summary = data.groupby('Cluster').mean(numeric_only=True)\n",
    "display(cluster_summary)\n",
    "\n",
    "cluster_summary.T.plot(kind='bar', figsize=(10,6), colormap='Set2')\n",
    "plt.title('Cluster Profiles by Feature Means')\n",
    "plt.ylabel('Average Values')\n",
    "plt.show()\n",
    "\n",
    "# --- Step 6: Export Results ---\n",
    "data.to_csv('Customer_Segmentation_Output.csv', index=False)\n",
    "print('Customer segmentation completed and results saved as Customer_Segmentation_Output.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
